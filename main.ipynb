{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde, poisson\n",
    "import tropycal.tracks as tracks\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "import geopandas as gpd\n",
    "import geodatasets\n",
    "from shapely import geometry, wkb, wkt\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import threading\n",
    "from queue import Queue\n",
    "import xarray as xr\n",
    "import pathlib\n",
    "import sqlite3\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Western Pacific (WP) locations: 5–60°N 100°–180°E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = re.compile('^MRI_HPB_m+\\d{3}.nc$')\n",
    "file_dirs = os.listdir('data')\n",
    "file_dirs\n",
    "# data_files = [f for f in file_dirs if s.match(f)]\n",
    "data_files_dirs = [pathlib.Path('data') / pathlib.Path(f) for f in file_dirs if s.match(f)]\n",
    "# data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_storms = xr.open_dataset(data_files_dirs[1])\n",
    "i = 0\n",
    "test_storms.track_lat[i]\n",
    "# for lat in test_storms.track_lat[i]:\n",
    "#     print(lat.values)\n",
    "test_storms.where((test_storms.track_lat >= 5) & (test_storms.track_lat <= 60) & (test_storms.track_lon >= 100) & (test_storms.track_lon <= 180), drop=True)\n",
    "# np.isnat(test_storms.track_time)\n",
    "# t = geometry.LineString(zip(test_storms.track_lon[i], test_storms.track_lat[i]))\n",
    "# b = t.wkb\n",
    "# b.hex()\n",
    "# tb = wkb.loads(b, hex=True)\n",
    "# tb\n",
    "# np.datetime_as_string(test_storms.track_time[1][3].values, unit='m')\n",
    "# data_files_dirs[1].stem\n",
    "type(test_storms.track_lat[0].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms_d = mp.Manager().dict()\n",
    "# storm_geo = mp.Manager().list()\n",
    "def create_storm_dict_task(storm_i, storms_d, storms, stem):\n",
    "    time_l = storms.track_time[storm_i].where(~np.isnat(storms.track_time[storm_i]), drop=True).values\n",
    "    lon_l = storms.track_lon[storm_i].where(~np.isnan(storms.track_lon[storm_i]), drop=True).values\n",
    "    lat_l = storms.track_lat[storm_i].where(~np.isnan(storms.track_lat[storm_i]), drop=True).values\n",
    "    pres_l = storms.track_pres[storm_i].where(~np.isnan(storms.track_pres[storm_i]), drop=True).values\n",
    "    wind_l = storms.track_wind[storm_i].where(~np.isnan(storms.track_wind[storm_i]), drop=True).values\n",
    "    # for i in range(len(storms.track_time[storm_i])):\n",
    "    #     # lat = storms.track_lat[storm_i][i]\n",
    "    #     # lon = storms.track_lon[storm_i][i]\n",
    "    #     if not np.isnan(storms.track_lon[storm_i][i]):\n",
    "    #         coords.append((storms.track_lon[storm_i][i], storms.track_lat[storm_i][i]))\n",
    "    #     else:\n",
    "    #         break\n",
    "    if len(lat_l) <= 1:\n",
    "        # print(f'{stem}_{storm_i} has no valid coordinates')\n",
    "        return\n",
    "    storms_d[f'{stem}_{storm_i}'] = {\n",
    "        # 'time': storms[i]['time'],\n",
    "        # 'geometry': geometry.LineString((lat, lon) for lat, lon in zip(storms.track_lon[storm_i], storms.track_lat[storm_i]) if (not np.isnan(lat) and not np.isnan(lon))),\n",
    "        # 'geometry': geometry.LineString(coords),\n",
    "        # 'featurecla': 'storm',\n",
    "        # 'scalerank': 1,\n",
    "        # 'min_zoom': 1,\n",
    "        'time': time_l,\n",
    "        'lat': lat_l,\n",
    "        'lon': lon_l,\n",
    "        'pres': pres_l,\n",
    "        'wind': wind_l\n",
    "        \n",
    "    }\n",
    "    # geometry_d.append(geometry.LineString((lat, lon) for lat, lon in zip(storms.track_lon[storm_i], storms.track_lat[storm_i]) if (not np.isnan(lat) and not np.isnan(lon))))\n",
    "    # print(storm_i)\n",
    "def generate_storm_dict(stem):\n",
    "    storms = xr.open_dataset(f'data/{stem}.nc')\n",
    "    filtered_storms = storms.where((storms.track_lat >= 5) & (storms.track_lat <= 60) & (storms.track_lon >= 100) & (storms.track_lon <= 180), drop=True)\n",
    "    # print(filtered_storms)\n",
    "    print(f\"{stem}\\n\", end='')\n",
    "    for storm_i in range(len(filtered_storms.storm)):\n",
    "        create_storm_dict_task(storm_i, storms_d, filtered_storms, stem)\n",
    "    # pool = mp.Pool(mp.cpu_count())\n",
    "    # pool.starmap(create_storm_dict_task, ((storm_i, storms_d, filtered_storms, stem) for storm_i in range(len(filtered_storms.storm))))\n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "# processes = []\n",
    "# for data in data_files_dirs:\n",
    "#     storms = xr.open_dataset(data)\n",
    "#     generate_storm_dict(storms, data.stem)\n",
    "\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "pool.starmap(generate_storm_dict, ([data.stem] for data in data_files_dirs))\n",
    "pool.close()\n",
    "pool.join()\n",
    "storms_d = storms_d._getvalue()\n",
    "    # processes.append(mp.Process(target=generate_geometry, args=(storms, data.stem)))\n",
    "    # generate_geometry(storms, data.stem)\n",
    "# for p in processes:\n",
    "#     p.start()\n",
    "# for p in processes:\n",
    "#     p.join()\n",
    "# storm_geo = storm_geo._getvalue()\n",
    "# print(storm_geo)\n",
    "# generate_geometry(test_storms, \"test\")\n",
    "# create_geometry(1203, storm_geo, test_storms, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('storms_d.p', 'wb') as f:\n",
    "    pickle.dump(storms_d, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('storms_d.p', 'rb') as f:\n",
    "    storms_d = pickle.load(f)\n",
    "storms_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world = gpd.read_file(geodatasets.get_path('naturalearth.land'))\n",
    "# df = pd.DataFrame.from_dict(storms_d, orient='index')\n",
    "# roi = gpd.GeoDataFrame(df, geometry='geometry', crs=world.crs)\n",
    "# roi\n",
    "# world_roi = pd.concat([world, roi])\n",
    "# world_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 2.25\n",
    "# res = 1.\n",
    "world = gpd.read_file(geodatasets.get_path('naturalearth.land'))\n",
    "storms = storms_d\n",
    "storms_df = pd.DataFrame.from_dict(storms, orient='index')\n",
    "lat_max = storms_df['lat'].apply(np.max).max()\n",
    "lat_min = storms_df['lat'].apply(np.min).min()\n",
    "lon_max = storms_df['lon'].apply(np.max).max()\n",
    "lon_min = storms_df['lon'].apply(np.min).min()\n",
    "time_min = storms_df['time'].apply(np.min).min()\n",
    "time_max = storms_df['time'].apply(np.max).max()\n",
    "year_num = (time_max-time_min).days/365.2425\n",
    "grids = np.zeros((round((lon_max-lon_min)/res)+1, round((lat_max-lat_min)/res)+1))\n",
    "for i in storms:\n",
    "    cell_coords = {}\n",
    "    coords = []\n",
    "    for lat, lon in zip(storms[i]['lat'], storms[i]['lon']):\n",
    "            # grids[round((lon-lon_min)/res), round((lat-lat_min)/res)] += 1\n",
    "            if (round((lon-lon_min)/res), round((lat-lat_min)/res)) not in coords:\n",
    "                coords.append((round((lon-lon_min)/res), round((lat-lat_min)/res)))\n",
    "    for i, j in coords:\n",
    "        grids[i, j] += 1\n",
    "            \n",
    "grids = grids/year_num * 0.1\n",
    "grid_cells = []\n",
    "X = []\n",
    "Y = []\n",
    "C = np.zeros((grids.shape[1], grids.shape[0]))\n",
    "\n",
    "for i in range(grids.shape[0]):\n",
    "    X.append(lon_min + (i+0.5)*res)\n",
    "for i in range(grids.shape[1]):\n",
    "    Y.append(lat_min + (i+0.5)*res)\n",
    "for i in range(grids.shape[0]):\n",
    "    for j in range(grids.shape[1]):\n",
    "        C[j, i] = grids[i, j]\n",
    "        \n",
    "lon_mesh, lat_mesh = np.meshgrid(X, Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = plt.matplotlib.colors.LogNorm(vmin=0.1, vmax=C.max())\n",
    "fig, ax = plt.subplots()\n",
    "world.plot(color='gray', edgecolor='black', ax=ax)\n",
    "ax.figure.set_size_inches(20, 15)\n",
    "ax.set_xlim(lon_min, lon_max)\n",
    "ax.set_ylim(lat_min, lat_max)\n",
    "cmap = plt.get_cmap('rainbow', 10)\n",
    "colors = cmap(np.linspace(0, 1, 256))\n",
    "colors[0][3] = 0\n",
    "cmap = plt.matplotlib.colors.ListedColormap(colors)\n",
    "pcm = ax.pcolormesh(lon_mesh, lat_mesh, C, cmap=cmap, shading='auto', alpha=0.8, norm=norm)\n",
    "cbar = fig.colorbar(pcm, ax=ax, orientation='vertical',\n",
    "                    extend='max',\n",
    "                    ticks=[0,0.1, 1, 10, 20, 30],\n",
    "                    pad=0.02)\n",
    "cbar.ax.set_title('[No./10yr]')\n",
    "cbar.ax.set_yticklabels(['0','0.1', '1', '10', '20', '30'])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(20, 10))\n",
    "# world.boundary.plot(ax=ax)\n",
    "# roi.plot(ax=ax, color='red', aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = [Dataset('data/' + f) for f in data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in datas[:10]:\n",
    "#     print(np.nanmax(data['track_lat'][:]), np.nanmin(data['track_lat'][:]), np.nanmax(data['track_lon'][:]), np.nanmin(data['track_lon'][:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = mp.Lock()\n",
    "# num_jobs = 0\n",
    "# def storm_data(storms, data, output):\n",
    "#     global num_jobs\n",
    "#     global l\n",
    "#     for i in range(0, data.dimensions['storm'].size):\n",
    "#         track_lat_any = np.array(data.variables['track_lat'][i])[\n",
    "#             (np.array(data.variables['track_lat'][i]) >= 5) &\n",
    "#             (np.array(data.variables['track_lat'][i]) <= 60) &\n",
    "#             (~np.isnan(np.array(data.variables['track_lat'][i])))\n",
    "#         ]\n",
    "#         track_lon_any = np.array(data.variables['track_lon'][i])[\n",
    "#             (np.array(data.variables['track_lon'][i]) >= 100) & \n",
    "#             (np.array(data.variables['track_lon'][i]) <= 180) &\n",
    "#             (~np.isnan(np.array(data.variables['track_lon'][i])))\n",
    "#         ]\n",
    "#         if len(track_lat_any) != 0 and len(track_lon_any) != 0:\n",
    "#             # print(data['track_lat'][i])\n",
    "#             pass\n",
    "#         else:\n",
    "#             continue\n",
    "#         storms[i] = {\n",
    "#             'time': data.variables['track_time'][i],\n",
    "#             'lat': data.variables['track_lat'][i],\n",
    "#             'lon': data.variables['track_lon'][i],\n",
    "#             'pres': data.variables['track_pres'][i],\n",
    "#             'wind': data.variables['track_wind'][i]\n",
    "#         }\n",
    "#     output.value += 1\n",
    "#     l.acquire()\n",
    "#     sys.stdout.write(f'\\rProgress: {output.value*100/num_jobs:.2f}% ({output.value} / {num_jobs})')\n",
    "#     sys.stdout.flush()\n",
    "#     l.release()\n",
    "# storms = mp.Manager().dict()\n",
    "# output = mp.Value('i', 0)\n",
    "# jobs = []\n",
    "# for data in datas:\n",
    "#     j = mp.Process(target=storm_data, args=(storms, data, output), daemon=True)\n",
    "#     jobs.append(j)\n",
    "#     num_jobs += 1\n",
    "#     print(f\"Creating jobs: {num_jobs}\", end=\"\\r\", flush=True)\n",
    "# print(\"\\nStarting jobs\")\n",
    "# _ = [j.start() for j in jobs]\n",
    "# _ = [j.join() for j in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(storms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storms = {}\n",
    "# for data in datas[:]:\n",
    "#     for i in range(0, data.dimensions['storm'].size):\n",
    "#     # for i in range(0, 10):\n",
    "#         track_lat_any = np.array(data.variables['track_lat'][i])[\n",
    "#             (np.array(data.variables['track_lat'][i]) >= 5) &\n",
    "#             (np.array(data.variables['track_lat'][i]) <= 60) &\n",
    "#             (~np.isnan(np.array(data.variables['track_lat'][i])))\n",
    "#         ]\n",
    "#         track_lon_any = np.array(data.variables['track_lon'][i])[\n",
    "#             (np.array(data.variables['track_lon'][i]) >= 100) & \n",
    "#             (np.array(data.variables['track_lon'][i]) <= 180) &\n",
    "#             (~np.isnan(np.array(data.variables['track_lon'][i])))\n",
    "#         ]\n",
    "#         if len(track_lat_any) != 0 and len(track_lon_any) != 0:\n",
    "#             # print(data['track_lat'][i])\n",
    "#             pass\n",
    "#         else:\n",
    "#             continue\n",
    "#         storms[i] = {\n",
    "#             'time': data.variables['track_time'][i],\n",
    "#             'lat': data.variables['track_lat'][i],\n",
    "#             'lon': data.variables['track_lon'][i],\n",
    "#             'pres': data.variables['track_pres'][i],\n",
    "#             'wind': data.variables['track_wind'][i]\n",
    "#         }\n",
    "# # storms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world = gpd.read_file(geodatasets.get_path('naturalearth.land'))\n",
    "# storm_geo = {}\n",
    "# for i in storms:\n",
    "#     storm_geo[i] = {\n",
    "#         # 'time': storms[i]['time'],\n",
    "#         'geometry': geometry.LineString((lat, lon) for lat, lon in zip(storms[i]['lon'], storms[i]['lat']) if (not np.isnan(lat) and not np.isnan(lon))),\n",
    "#         'featurecla': 'storm',\n",
    "#         'scalerank': 1,\n",
    "#         'min_zoom': 1,\n",
    "#     }\n",
    "# df = pd.DataFrame.from_dict(storm_geo, orient='index')\n",
    "# roi = gpd.GeoDataFrame(df, geometry='geometry', crs=world.crs)\n",
    "# roi\n",
    "# world_roi = pd.concat([world, roi])\n",
    "# world_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = 2.25\n",
    "# lat_max = np.nanmax([np.nanmax(storms[i]['lat']) for i in storms])\n",
    "# lat_min = np.nanmin([np.nanmin(storms[i]['lat']) for i in storms])\n",
    "# lon_max = np.nanmax([np.nanmax(storms[i]['lon']) for i in storms])\n",
    "# lon_min = np.nanmin([np.nanmin(storms[i]['lon']) for i in storms])\n",
    "# grids = np.zeros((int((lat_max-lat_min)/res)+1, int((lon_max-lon_min)/res)+1))\n",
    "# for i in storms:\n",
    "#     cell_coords = {}\n",
    "#     for lat, lon in zip(storms[i]['lat'], storms[i]['lon']):\n",
    "#         if (not np.isnan(lat) and not np.isnan(lon)):\n",
    "#             cell_coords[int((lat-lat_min)/res), int((lon-lon_min)/res)] = 1\n",
    "#     for coord in cell_coords:\n",
    "#         grids[coord] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_cells = []\n",
    "# for i in range(grids.shape[0]):\n",
    "#     for j in range(grids.shape[1]):\n",
    "#         grid_cells.append({\n",
    "#             'geometry': geometry.Polygon([(lon_min + j*res, lat_min + i*res), (lon_min + j*res, lat_min + (i+1)*res), (lon_min + (j+1)*res, lat_min + (i+1)*res), (lon_min + (j+1)*res, lat_min + i*res)]),\n",
    "#             'storm_count': grids[i, j]\n",
    "#         })\n",
    "# grid_df = pd.DataFrame(grid_cells)\n",
    "# grid_gdf = gpd.GeoDataFrame(grid_df, geometry='geometry', crs=world.crs)\n",
    "# ax = world.plot(color='green', edgecolor='red')\n",
    "# ax.figure.set_size_inches(20, 15)\n",
    "# ax.set_xlim(lon_min, lon_max)\n",
    "# ax.set_ylim(lat_min, lat_max)\n",
    "# grid_gdf.plot(column='storm_count', ax=ax, legend=True, cmap='RdYlBu_r', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
